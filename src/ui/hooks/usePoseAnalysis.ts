// src/ui/hooks/usePoseAnalysis.ts (TensorFlow.js runtimeç‰ˆ)

import { useEffect, useRef, useState } from 'react';
import * as poseDetection from '@tensorflow-models/pose-detection';
import '@tensorflow/tfjs-backend-webgl';
import { Landmark } from '../../types';
import { useAppStore } from '../../state/store';

export const usePoseAnalysis = (videoElement: HTMLVideoElement | null) => {
  const [detector, setDetector] = useState<poseDetection.PoseDetector | null>(null);
  const [isModelReady, setIsModelReady] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [isInitializing, setIsInitializing] = useState(true);
  
  // useRefã‚’ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã§å®£è¨€
  const animationFrameRef = useRef<number>();
  const frameCountRef = useRef(0);
  const startTimeRef = useRef(0);
  
  const { 
    testStatus, 
    currentTest,
    updateLandmarks
  } = useAppStore();

  // TensorFlow.js BlazePoseåˆæœŸåŒ–
  useEffect(() => {
    let isMounted = true;
    
    const initializePoseDetector = async () => {
      try {
        setError(null);
        setIsInitializing(true);
        
        console.log('ğŸš€ TensorFlow.js BlazePoseåˆæœŸåŒ–é–‹å§‹...');
        
        const model = poseDetection.SupportedModels.BlazePose;
        const detectorConfig = {
          runtime: 'tfjs' as const,
          modelType: 'lite' as const,
          enableSmoothing: true,
          enableSegmentation: false
        };
        
        const poseDetector = await poseDetection.createDetector(model, detectorConfig);
        
        if (!isMounted) return;
        
        console.log('âœ… TensorFlow.js BlazePoseåˆæœŸåŒ–å®Œäº†');
        setDetector(poseDetector);
        setIsModelReady(true);
        setIsInitializing(false);
        
      } catch (err) {
        console.error('âŒ TensorFlow.js BlazePoseåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:', err);
        if (isMounted) {
          setError(`TensorFlow.js BlazePoseã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: ${err instanceof Error ? err.message : String(err)}`);
          setIsInitializing(false);
        }
      }
    };

    initializePoseDetector();
    
    return () => {
      isMounted = false;
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    };
  }, []);

  // ãƒ“ãƒ‡ã‚ªè§£æãƒ«ãƒ¼ãƒ—
  useEffect(() => {
    if (!detector || !videoElement || testStatus !== 'running') {
      return;
    }

    let lastVideoTime = -1;

    const detectPose = async () => {
      try {
        if (!videoElement || !detector || testStatus !== 'running') {
          return;
        }

        const currentTime = videoElement.currentTime;
        
        if (currentTime !== lastVideoTime) {
          lastVideoTime = currentTime;
          frameCountRef.current++;
          
          // ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆåˆ¶å¾¡ï¼ˆ15fpsç›®å®‰ï¼‰
          if (frameCountRef.current % 2 !== 0) {
            animationFrameRef.current = requestAnimationFrame(detectPose);
            return;
          }

          console.log('ğŸ¬ TensorFlow.js pose detection...');

          const poses = await detector.estimatePoses(videoElement);
          
          if (poses && poses.length > 0 && poses[0].keypoints) {
            const detectedLandmarks: Landmark[] = poses[0].keypoints.map(keypoint => ({
              x: keypoint.x / videoElement.videoWidth,  // æ­£è¦åŒ–ï¼ˆ0-1ï¼‰
              y: keypoint.y / videoElement.videoHeight, // æ­£è¦åŒ–ï¼ˆ0-1ï¼‰
              z: 0, // 2Dãƒ¢ãƒ¼ãƒ‰ã§ã¯0
              visibility: keypoint.score || 1.0
            }));
            
            // ã‚¢ãƒ—ãƒªç”¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
            const timestamp = Date.now();
            updateLandmarks(detectedLandmarks, timestamp);
            
            console.log('âœ… TensorFlow.js ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡º:', detectedLandmarks.length + 'å€‹');
          }

          // 10ç§’ã§ãƒ†ã‚¹ãƒˆçµ‚äº†
          const elapsed = Date.now() - startTimeRef.current;
          if (elapsed > 10000) {
            console.log('âœ… ãƒ†ã‚¹ãƒˆå®Œäº†ï¼ˆ10ç§’çµŒéï¼‰');
            return;
          }
        }
        
        animationFrameRef.current = requestAnimationFrame(detectPose);
      } catch (err) {
        console.error('ğŸ”´ TensorFlow.js Pose detection error:', err);
        setError(`ãƒãƒ¼ã‚ºæ¤œå‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${err instanceof Error ? err.message : String(err)}`);
      }
    };

    if (testStatus === 'running') {
      startTimeRef.current = Date.now();
      frameCountRef.current = 0;
      detectPose();
    }

    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    };
  }, [detector, videoElement, testStatus, currentTest, updateLandmarks]);

  return {
    isModelReady,
    error,
    isInitializing
  };
};
