// src/ui/hooks/usePoseAnalysis.ts (ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä¿®æ­£ç‰ˆ)

import { useEffect, useRef, useState } from 'react';
import { PoseLandmarker, FilesetResolver } from '@mediapipe/tasks-vision';
import { Landmark } from '../../types';
import { useAppStore } from '../../state/store';

export const usePoseAnalysis = (videoElement: HTMLVideoElement | null) => {
  const [poseLandmarker, setPoseLandmarker] = useState<PoseLandmarker | null>(null);
  const [isModelReady, setIsModelReady] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [isInitializing, setIsInitializing] = useState(true);
  
  // useRefã‚’ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã§å®£è¨€
  const animationFrameRef = useRef<number>();
  const frameCountRef = useRef(0);
  const startTimeRef = useRef(0);
  const lastTimestampRef = useRef(0); // MediaPipeã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç®¡ç†
  
  const { 
    testStatus, 
    currentTest,
    updateLandmarks
  } = useAppStore();

  // MediaPipeåˆæœŸåŒ–ï¼ˆruntime = mediapipeæ˜ç¤ºï¼‰
  useEffect(() => {
    let isMounted = true;
    
    const initializePoseLandmarker = async () => {
      try {
        setError(null);
        setIsInitializing(true);
        
        console.log('ğŸš€ MediaPipeåˆæœŸåŒ–é–‹å§‹...');
        
        const vision = await FilesetResolver.forVisionTasks(
          'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'
        );
        
        if (!isMounted) return;
        
        console.log('ğŸ“¦ MediaPipe Wasmãƒ­ãƒ¼ãƒ‰å®Œäº†');
        
        const landmarker = await PoseLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',
            delegate: 'GPU'
          },
          runningMode: 'VIDEO',
          numPoses: 1,
          minPoseDetectionConfidence: 0.5,
          minPosePresenceConfidence: 0.5,
          minTrackingConfidence: 0.5,
          outputSegmentationMasks: false
        });
        
        if (!isMounted) return;
        
        console.log('âœ… PoseLandmarkeråˆæœŸåŒ–å®Œäº†');
        setPoseLandmarker(landmarker);
        setIsModelReady(true);
        setIsInitializing(false);
        
      } catch (err) {
        console.error('âŒ MediaPipeåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:', err);
        if (isMounted) {
          setError(`MediaPipeã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: ${err instanceof Error ? err.message : String(err)}`);
          setIsInitializing(false);
        }
      }
    };

    initializePoseLandmarker();
    
    return () => {
      isMounted = false;
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    };
  }, []);

  // ãƒ“ãƒ‡ã‚ªè§£æãƒ«ãƒ¼ãƒ—
  useEffect(() => {
    if (!poseLandmarker || !videoElement || testStatus !== 'running') {
      return;
    }

    let lastVideoTime = -1;

    const detectPose = async () => {
      try {
        if (!videoElement || !poseLandmarker || testStatus !== 'running') {
          return;
        }

        const currentTime = videoElement.currentTime;
        
        if (currentTime !== lastVideoTime) {
          lastVideoTime = currentTime;
          frameCountRef.current++;
          
          // ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆåˆ¶å¾¡ï¼ˆ15fpsç›®å®‰ï¼‰
          if (frameCountRef.current % 2 !== 0) {
            animationFrameRef.current = requestAnimationFrame(detectPose);
            return;
          }

          // MediaPipeç”¨ã®å˜èª¿å¢—åŠ ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç”Ÿæˆ
          const currentTimestamp = performance.now();
          
          // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒå‰å›ã‚ˆã‚Šå¤§ãã„ã“ã¨ã‚’ä¿è¨¼
          if (currentTimestamp <= lastTimestampRef.current) {
            lastTimestampRef.current += 1; // æœ€å°é™å¢—åŠ 
          } else {
            lastTimestampRef.current = currentTimestamp;
          }

          console.log('ğŸ¬ MediaPipe timestamp:', lastTimestampRef.current);

          const results = await poseLandmarker.detectForVideo(videoElement, lastTimestampRef.current);
          
          if (results.landmarks && results.landmarks.length > 0) {
            const detectedLandmarks: Landmark[] = results.landmarks[0].map(landmark => ({
              x: landmark.x,
              y: landmark.y,
              z: landmark.z || 0,
              visibility: landmark.visibility || 1.0
            }));
            
            // ã‚¢ãƒ—ãƒªç”¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆåˆ¥ç®¡ç†ï¼‰
            const appTimestamp = Date.now();
            updateLandmarks(detectedLandmarks, appTimestamp);
            
            console.log('âœ… ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡º:', detectedLandmarks.length + 'å€‹');
          }

          // 10ç§’ã§ãƒ†ã‚¹ãƒˆçµ‚äº†
          const elapsed = Date.now() - startTimeRef.current;
          if (elapsed > 10000) {
            // è‡ªå‹•çš„ã«ãƒ†ã‚¹ãƒˆå®Œäº†ï¼ˆã‚¹ãƒˆã‚¢å†…ã§å‡¦ç†ã•ã‚Œã‚‹ï¼‰
            console.log('âœ… ãƒ†ã‚¹ãƒˆå®Œäº†ï¼ˆ10ç§’çµŒéï¼‰');
            return;
          }
        }
        
        animationFrameRef.current = requestAnimationFrame(detectPose);
      } catch (err) {
        console.error('ğŸ”´ Pose detection error:', err);
        setError(`ãƒãƒ¼ã‚ºæ¤œå‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${err instanceof Error ? err.message : String(err)}`);
      }
    };

    if (testStatus === 'running') {
      startTimeRef.current = Date.now();
      frameCountRef.current = 0;
      lastTimestampRef.current = 0; // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒªã‚»ãƒƒãƒˆ
      detectPose();
    }

    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    };
  }, [poseLandmarker, videoElement, testStatus, currentTest, updateLandmarks]);

  return {
    isModelReady,
    error,
    isInitializing
  };
};
